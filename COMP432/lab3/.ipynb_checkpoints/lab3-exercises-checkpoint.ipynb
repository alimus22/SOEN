{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Exercises for COMP 6321 Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you'll cluster and fit mixture models to data using the popular _scikit-learn_ package. Lab3 requires a good understanding of Numpy and Matplotlib. Please complete Lab1 before attempting Lab3.\n",
    "\n",
    "**Run the code cell below** to import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.cluster         # For KMeans class\n",
    "import sklearn.mixture         # For GaussianMixture class\n",
    "import sklearn.preprocessing   # For scale function\n",
    "import mpl_toolkits.mplot3d    # For enabling projection='3d' feature in Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Introduction\n",
    "This \"introduction\" group of code cells has no exercises. The goal is to provide you with examples. Run the code cells and learn from them.\n",
    "\n",
    "Load the image *ladybug.png* as a Numpy array. The image should already have been unzipped into the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread('ladybug.png')\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the shape of the array. Entry _image[y,x]_ in the array is a length-3 vector representing the RGB value of pixel at location $(x, y)$ in the image.\n",
    "\n",
    "Plot the image using Matplotlib's _imshow_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the image into a 2-dimensional matrix suitable for clustering the pixels by their RGB colour value. The data should be in array format \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "r_1 & g_1 & b_1\\\\\n",
    "r_2 & g_2 & b_2\\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "r_N & g_N & b_N\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $N=10000$ and each $\\begin{bmatrix} r_i & g_i & b_i \\end{bmatrix}$ is the colour of pixel with index $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB = image.reshape(-1, 3)\n",
    "print(RGB.shape)\n",
    "print(RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-left pixel (index $i=0$) has colour $\\begin{bmatrix} 0.31 & 0.56 & 0.20 \\end{bmatrix}$, which is green-ish. Makes sense! \n",
    "\n",
    "Plot the pixel RGB values in 3-dimensional colour space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colour_space(RGB, title=None, hold=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots Nx3 matrix RGB in 3 dimensions.\n",
    "    \n",
    "    The keyword arguments are passed to Matplotlib's scatter() function.\n",
    "    If hold=True, the points will be added to the previous plot. Otherwise a new plot is generated.\n",
    "    \"\"\"\n",
    "    if hold:\n",
    "        ax = plt.gca()\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    kwargs.setdefault('alpha', 1.0)\n",
    "    ax.scatter(*RGB.T, **kwargs)\n",
    "    ax.set_xlabel('R', color='r', fontweight='bold', fontsize=15)\n",
    "    ax.set_ylabel('G', color='g', fontweight='bold', fontsize=15)\n",
    "    ax.set_zlabel('B', color='b', fontweight='bold', fontsize=15)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "plot_colour_space(RGB, c=RGB, s=0.5, marker='s', title=\"Pixels plotted in colour space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the *K*-means clustering algorithm with *K*=5, using each RGB pixel colour vector as a data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(data, k):\n",
    "    \"\"\"\n",
    "    Runs K-means on an NxD array using k clusters.\n",
    "    \n",
    "    Returns a KxD matrix of centroids and a length-N vector of labels (cluster assignments).\n",
    "    \"\"\"\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=k, random_state=0).fit(data)\n",
    "    return kmeans.cluster_centers_, kmeans.labels_\n",
    "\n",
    "centroids, labels = run_kmeans(RGB, k=5)\n",
    "\n",
    "print(centroids)\n",
    "print(labels, len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The centroids array has shape (5,3) because there are *K*=5 centroids, a 3-dimensional vector. The labels are given as integer indices, as in the \"alternate formulation for *K*-means\" from Lecture 2.\n",
    "\n",
    "Plot the centroids in RGB colour space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_colour_space(centroids, facecolors=centroids, edgecolor='black', s=1000, title=\"Centroids only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the pixels in RGB space but with colour matching that of the centroid the pixel was assigned to. Include the centroids themselves in the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new (10000,3) ndarray where values in row i are copied from centroids[labels[i],:]\n",
    "RGB_recoloured = centroids[labels]\n",
    "\n",
    "# Plot the re-coloured pixels, along with the corresponding centroids\n",
    "plot_colour_space(RGB, c=RGB_recoloured, marker='s', s=0.5, title=\"Centroids and recoloured pixels\")\n",
    "plot_colour_space(centroids, facecolors=centroids, edgecolor='black', s=1000, hold=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(RGB_recoloured.reshape(image.shape));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the above to Figure 9.3 (p.429) of the Bishop textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 1. Spatial clustering with K-means\n",
    "\n",
    "Exercises 1.1&ndash;1.4 ask you to apply scikit-learn's **[sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)** object to the pixels from the introduction, but on slightly different data.\n",
    "\n",
    "It requires that you have already **run the code cells from the introduction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'image' in globals(), \"Did you run the code cells from introduction?\"\n",
    "assert 'RGB' in globals(), \"Did you run the code cells from introduction?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 1.1 &mdash; Add pixel location features\n",
    "\n",
    "The introduction showed you how to cluster pixels by colour, like Figure 9.3 (p.429) of the Bishop book. The data that we clustered was an array of 3-dimensional features $\\begin{bmatrix} r_i & g_i & b_i \\end{bmatrix}$, stored in the array object referenced by variable *RGB*. \n",
    "\n",
    "\n",
    "In exercises 1.2&ndash;1.4, you'll be asked to cluster the pixels by _colour_ (rgb) and _location_ (xy). To do this, you must first add pixel location features to the data.\n",
    "\n",
    "\n",
    "**Write a few lines of code** to create a new array called *RGBXY* where each row is a 5-dimensional feature vector $\\begin{bmatrix} r_i & g_i & b_i & x_i & y_i\\end{bmatrix}$, with $(x_i, y_i)$ being the location in the image where pixel $i$ came from in the original image. Use the *image* variable to get the height and width of the original ladybug image. Then use the [**np.arange**](https://numpy.org/doc/stable/reference/generated/numpy.arange.html) and [**np.meshgrid**](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) function to generate two arrays, each containing the individual $x_i$ and $y_i$ values respectively. Finally, use a matrix stacking function like [**np.column_stack**](https://numpy.org/doc/stable/reference/generated/numpy.column_stack.html) to create the new array object *RGBXY* from the original *RGB* data and your new pixel location arrays.\n",
    "\n",
    "If you have done everything correctly, your data with extra \"pixel location features\" should look like this:\n",
    "```python\n",
    ">>> RGBXY\n",
    "[[ 0.30588236  0.55686277  0.2         0.          0.        ]\n",
    " [ 0.27058825  0.53333336  0.16470589  1.          0.        ]\n",
    " [ 0.27058825  0.53333336  0.16470589  2.          0.        ]\n",
    " ...\n",
    " [ 0.4509804   0.67450982  0.34901962 97.         99.        ]\n",
    " [ 0.43921569  0.67843139  0.34509805 98.         99.        ]\n",
    " [ 0.46666667  0.6901961   0.37254903 99.         99.        ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-6 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your answer** by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'RGBXY' in globals(), \"You didn't create a variable called RGBXY\"\n",
    "assert isinstance(RGBXY, np.ndarray), \"Expected RGBXY to be ndarray\"\n",
    "assert RGBXY.dtype == RGB.dtype, \"RGBXY has wrong dtype\"\n",
    "assert RGBXY.shape == (100*100,5), \"RGBXY has wrong shape\"\n",
    "assert np.array_equal(RGBXY[99:101],\n",
    "                      np.array([[0.38039216, 0.57647060, 0.15686275, 99., 0.],\n",
    "                                [0.25490198, 0.52156866, 0.14509805,  0., 1.]], dtype=np.float32)), \"RGBXY wrong data\"                      \n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 1.2 &mdash; Cluster pixels spatially\n",
    "\n",
    "**Write a few lines of code** to do the following:\n",
    "1. Cluster the $\\begin{bmatrix} r_i & g_i & b_i & x_i & y_i\\end{bmatrix}$ values that are currently stored in the _RGBXY_ variable. Use *K*=6 clusters. You can use *sklearn.cluster.KMeans* directly or you can use the _run_kmeans_ function from the introduction.\n",
    "2. Plot the re-coloured image, where each pixel's colour has been replaced by its corresponding centroid colour, as we did in the introduction.\n",
    "\n",
    "Your plot should look like this:\n",
    "![image](img/fig-ladybug-kmeans-spatial.png)\n",
    "\n",
    "_Hint:_ Your _RGBXY_ array has shape (10000,5), but the _imshow_ function expects an array of shape (*height*, *width*, 3). So you will need to slice out colour data and reshape it into a form that _imshow_ expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your code here. Aim for 4-6 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 1.3 &mdash; More clusters!\n",
    "\n",
    "**Repeat Exercise 1.2** but this time use *K*=50 clusters. It may take a few seconds. If you do not understand the result that you see, ask for insight from a TA or from someone else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-6 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 1.4 &mdash; Feature scaling\n",
    "\n",
    "**Repeat Exercise 1.3** but this time scale the $x$ and $y$ features by a factor of 0.02 before clustering. Your answer should use Numpy's \"broadcasting\" mechanism to achieve the scaling in a single step.\n",
    "\n",
    "Be sure to store the transformed values in a new array called _RGBXY_scaled_ rather than modifying the original _RGBXY_ array. Otherwise you may end up having to re-run the code cell that generated the _RGBXY_ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here. Aim for 3-7 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to see that the clustering method is very sensitive to the scale of different features. If you were to scale the _XY_ components all the way to zero, you would be back to clustering _only by colour_, as we did in the introduction.\n",
    "\n",
    "Before continuing, try scaling $(x,y)$ by different values, such as $(0.05, 0.02)$ and see how that effects the pixel clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 2. Selecting *K* in *K*-means\n",
    "\n",
    "Exercises 2.1&ndash;2.2 ask you to generate synthetic data and to apply the \"elbow\" heuristic for selecting optimal *K* in *K*-means.\n",
    "\n",
    "**Run the code cell below** to define a function for sampling data from a mixture of Gaussians. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gmm(means, covs=None, weights=None, N=1):\n",
    "    \"\"\"\n",
    "    Samples a K-component D-dimensional Gaussian mixture.\n",
    "    \n",
    "    The means are KxD.\n",
    "    The covariances are KxDxD. The default covariance is the DxD identity matrix.\n",
    "    The weights are length K and must sum to 1. The default is uniform weights.\n",
    "    \n",
    "    Returns (X, c) where X is an NxD array of samples and c is a length-N vector\n",
    "    of component indices, i.e. X[i] was sampled from mixture component c[i].\n",
    "    \"\"\"\n",
    "    K, D = means.shape\n",
    "    \n",
    "    # Valudate inputs and set default values if needed\n",
    "    if covs is None:\n",
    "        covs = np.tile(np.eye(D), (K,1,1))  # Stack of K D-dimensional identity matricies\n",
    "    if weights is None:\n",
    "        weights = np.full(K, 1/K)\n",
    "    assert covs.shape == (K,D,D)\n",
    "    \n",
    "    # Sample a vector of component choices in proportion to weights, one for each sample\n",
    "    c = np.random.choice(K, N, p=weights)  # choice() checks that weights has shape (K,1) and sums to 1\n",
    "    \n",
    "    # Fill an array of N samples, one component at a time\n",
    "    X = np.empty((N,D))\n",
    "    for k in range(K):\n",
    "        X[k==c] = np.random.multivariate_normal(means[k], covs[k], np.count_nonzero(k==c))\n",
    "    return X, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 2.1 &mdash; Generate synthetic GMM data\n",
    "\n",
    "**Write a few lines of code** to generate 1000 samples from a 9-component Gaussian mixture, where the means are arranged in a 3x3 grid as shown below.\n",
    "\n",
    "![image](img/fig-synthetic-gmm-data-1.png)\n",
    "\n",
    "Use a single call to the *sample_gmm* function to generate your data. That means you must build a _means_ matrix with shape (9,2) containing the 9 means. You should know how to do this procedurally, either with for-loops or with a call to the _np.meshgrid_ and *np.column_stack* functions. (Do not write out all 9 of the mean vectors by hand.)\n",
    "\n",
    "Create a variable called _X_ that refers to your samples, and create a variable called _c_ that refers to the mixture component indices (this value is directly returned by *sample_gmm*, so just store the result).\n",
    "\n",
    "The `np.random.seed(0)` ensures you always generate the same data each time you run the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Your code here. Aim for 3-6 additional lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot your data** by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'X' in globals(), \"You must create a variable called 'X' that refers to your samples!\"\n",
    "assert 'c' in globals(), \"You must create a variable called 'c' that refers to your component indices!\"\n",
    "assert X.shape == (1000,2), \"X should have shape (1000, 2)!\"\n",
    "assert c.shape == (1000,), \"c should have shape (1000,)!\"\n",
    "plt.scatter(*X.T, c=c, s=5)     # Plot each point (X[i,0], X[i,1]) using colour index c[i] and point size 5\n",
    "plt.title(\"Synthetic GMM data\")\n",
    "plt.xticks([-5, 0, 5])\n",
    "plt.yticks([-5, 0, 5])\n",
    "plt.gca().set_aspect('equal')   # It's important to see this data with equal scales on each axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 2.2 &mdash; Choosing *K* with *K*-means\n",
    "\n",
    "When applying *K*-means, it may be difficult to choose the best *K* for a particular data set. Recall the \"elbow curve\" method for selecting *K* as reviewed in Lecture 2. You are asked to apply this method to select a \"good\" *K* for the data set generated in Exercise 2.1.\n",
    "\n",
    "**Write a few lines of code** to generate a plot of *K* ($x$-axis) versus the corresponding *K*-means objective value ($y$-axis) for each choice of $K \\in \\{2, \\ldots 15\\}$. Use the **[sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)** object in your answer. Once you have called the _fit_ method on a _KMeans_ object you can recover the final objective value (at convergence) from the object's *intertia_* attribute (as in `kmeans_object.inertia_`).\n",
    "\n",
    "If you have done this correctly, you should see a 'kink' at *K*=9, which makes sense given that the data was indeed generated from 9 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-4 lines of code plus a few lines for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 3. Fitting a Gaussian Mixture Model (GMM)\n",
    "\n",
    "Exercises 3.1&ndash;3.4 ask you fit 2D data with scikit-learn's **[sklearn.mixture.GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)** object.\n",
    "\n",
    "**Run the code cell below** to define a function that will help to visualize the placement and shape of GMM components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gmm(gmm):\n",
    "    \"\"\"\n",
    "    Plots the placement of components in a Gaussian Mixture.\n",
    "    \n",
    "    The gmm object should be of type sklean.mixture.GaussianMixture\n",
    "    \"\"\"\n",
    "    ax = plt.gca()\n",
    "    for weight, mean, cov in zip(gmm.weights_, gmm.means_, gmm.covariances_):\n",
    "        v, w = np.linalg.eigh(cov)\n",
    "        v = 2*np.sqrt(2*v)\n",
    "        u = w[0] / np.linalg.norm(w[0])\n",
    "        angle = 180 * (1 + np.arctan(u[1]/u[0]) / np.pi)  # Ellipse() function needs degrees\n",
    "        ell = mpl.patches.Ellipse(mean, v[0], v[1], angle, edgecolor='k',\n",
    "                                  facecolor='none', linestyle='--', linewidth=2, alpha=0.8)\n",
    "        ax.add_artist(ell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 3.1 &mdash; Fit a GMM to non-overlapping, isotropic data\n",
    "\n",
    "**Write fitting code** to fit a **[sklearn.mixture.GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)** object to the synthetic data from Exercise 2.1. Use 9 mixture components in your answer. You should use the argument *random_state=0* to ensure reproducibility. Create a variable called _gmm_ that refers to your new *GaussianMixture* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here. Aim for 1-2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write plotting code** using the *plot_gmm* function provided. Once you have the ellipses plotting correctly, use the **[predict](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture.predict)** method of the *GaussianMixture* object and use them to colour the points in the scatter plot. Your plot should look similar to:\n",
    "![image](img/fig-synthetic-gmm-fit-1.png)\n",
    "If you find that the GMM components do not fit perfectly to the data, try adding *n_init=5* to the arguments of your _GaussianMixture_ object. This will run the EM algorithm multiple times from different randomized initializations, and may give a higher chance of getting the 'right' clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modify the code below. Aim for 2 additional lines.\n",
    "plt.scatter(*X.T, s=5)\n",
    "plt.title('GMM fitted to anisotropic data')\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 3.2 &mdash; Generate overlapping, anisotropic synthetic GMM data\n",
    "\n",
    "**Write some code** to generate 500 samples from 2-dimensional 3-component Gaussian mixture having the following parameters:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pi_1 = 0.5, \\quad &\\boldsymbol{\\mu}_1 = \\begin{bmatrix} -2.0 & 0.0 \\end{bmatrix}, &\\boldsymbol{\\Sigma}_1 = \\begin{bmatrix}\\phantom{-}2.0 & \\phantom{-}1.0 \\\\ \\phantom{-}1.0 & \\phantom{-}2.0\\end{bmatrix}\\\\\n",
    "\\pi_2 = 0.3, \\quad &\\boldsymbol{\\mu}_2 = \\begin{bmatrix} \\phantom{-}2.0 & 0.0 \\end{bmatrix}, &\\boldsymbol{\\Sigma}_2 = \\begin{bmatrix}1.0 & -0.9 \\\\ -0.9 & 1.0\\end{bmatrix}\\\\\n",
    "\\pi_3 = 0.2, \\quad &\\boldsymbol{\\mu}_3 = \\begin{bmatrix} \\phantom{-}0.0 & 0.0 \\end{bmatrix}, &\\boldsymbol{\\Sigma}_3 = \\begin{bmatrix}10.0 & \\phantom{-}0.0 \\\\ \\phantom{-}0.0 & 10.0\\end{bmatrix}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Use the *sample_gmm* function from part 2. Create a variable called _X_ that refers to your samples, and create a variable called _c_ that refers to the mixture component indices (this value is directly returned by *sample_gmm*, so just store the result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Your code here. Use however many lines you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot your data** by running the code cell below. The plot should look like this:\n",
    "![image](img/fig-synthetic-gmm-data-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'X' in globals(), \"You must create a variable called 'X' that refers to your samples!\"\n",
    "assert 'c' in globals(), \"You must create a variable called 'c' that refers to your component indices!\"\n",
    "assert X.shape == (500,2), \"X should have shape (500, 2)!\"\n",
    "assert c.shape == (500,), \"c should have shape (500,)!\"\n",
    "plt.scatter(*X.T, c=c, s=5)     # Plot each point (X[i,0], X[i,1]) using colour index c[i] and point size 5\n",
    "plt.title(\"Synthetic GMM data\")\n",
    "plt.xticks([-5, 0, 5])\n",
    "plt.yticks([-5, 0, 5])\n",
    "plt.gca().set_aspect('equal')   # It's important to see this data with equal scales on each axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 3.3 &mdash; Fit a GMM to the anisotropic, overlapping data\n",
    "\n",
    "**Write fitting code** to fit a **[sklearn.mixture.GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)** object to the synthetic data you generated in Exercise 3.2. Use 3 mixture components in your answer. You should use the argument *random_state=0* to ensure reproducibility. Create a variable called _gmm_ that refers to your new *GaussianMixture* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your code here. Aim for 1-2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write plotting code** (like Exercise 3.1) using the **[predict](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture.predict)** method. Your plot should look like this (colours may differ):\n",
    "![image](img/fig-synthetic-gmm-fit-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modify the code below. Aim for 2 additional lines.\n",
    "plt.scatter(*X.T, s=5)\n",
    "plt.title('GMM fitted to anisotropic data')\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write plotting code** to visualize the probability $p(z_{ik} \\mid \\mathbf{x}_i)$ that component $k$ generated data point $\\mathbf{x}_i$. Use the **[predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture.predict_proba)** method of the _GaussianMixture_ object to get the probabilities. Because there are $K=3$ components, you can visualize these probabilities by using $\\begin{bmatrix} p(z_{i1} \\mid \\mathbf{x}_i) & p(z_{i2} \\mid \\mathbf{x}_i) & p(z_{i3} \\mid \\mathbf{x}_i) \\end{bmatrix}$ as the values colour $\\begin{bmatrix} r_i & g_i & b_i \\end{bmatrix}$ for data point $i$. Your plot should look like this:\n",
    "![image](img/fig-synthetic-gmm-fit-2-probs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the code below. Aim for 2 additional lines.\n",
    "plt.scatter(*X.T, s=20)\n",
    "plt.title('GMM responsibilities')\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 3.4 &mdash; Sample from spatially clustered pixels using a GMM\n",
    "\n",
    "**Write fitting code** to fit a **[sklearn.mixture.GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)** object to the _RGBXY_ data (the ladybug) that you generated in Exercise 1.2. Use **15** mixture components in your answer. You should use the argument *random_state=0* to ensure reproducibility. Create a variable called _gmm_ that refers to your new *GaussianMixture* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 1-2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate 5000 samples** from your fitted mixture model by using the **[sample](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture.sample)** method of the _GaussianMixture_ object. The resulting sample matrix should have shape (5000,5) where each row is a vector $\\begin{bmatrix}r & g & b & x & y\\end{bmatrix}$. Create a variable _X_ to refer to your new samples. Note that the _sample_ function also returns a component membership vector, but you can ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 1 line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the samples** as if they were pixels at location $(x,y)$ with colour $(r,g,b)$. Use a single call to Matplotlib's _scatter_ function. Your ladybug should look something like this:\n",
    "![image](img/fig-synthetic-ladybug.png)\n",
    "\n",
    "*Hint:* The _scatter_ function will fail if you use any colour values outside range $[0.0,1.0]$, yet there's no guarantee that a Gaussian will produce values within this range. Use the **[np.clip](https://numpy.org/devdocs/reference/generated/numpy.clip.html)** function to clamp the $(r,g,b)$ values to this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-5 lines.\n",
    "\n",
    "# Keep these lines at the end.\n",
    "plt.gca().invert_yaxis()         # This line makes sure the ladybug appears upright!\n",
    "plt.gca().set_aspect('equal')    # This line makes sure the ladybug isn't squished!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final exercise was designed to show:\n",
    "* how to train a GMM on 5-dimensional data (RGBXY);\n",
    "* how to visualize 5 dimensional samples in a 2D plot, by using a combination of colour and space;\n",
    "* that sampling from a generative model, such as a GMM, is a good way to see whether the samples it generates are \"realistic\" or whether they're missing important aspects of the real data; and\n",
    "* that a Gaussian or a GMM, when used as a generative model, can produce samples that have values outside the range of the original training data (for example, negative XY coordinates)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
